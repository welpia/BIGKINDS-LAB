# -*- coding: utf-8 -*-
"""2.1 LDA - 8개 대분류 기준 하위 중분류 분석 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HThnrUf1m-aC5Agk6cKSAgvFEnF1SloT
"""

import pickle
import numpy  as np
import pandas as pd

from gensim                       import corpora 
from gensim.models.callbacks      import CoherenceMetric  # 이 값이 작을수록 해당 토픽 모델은 실제 문헌 결과를 잘 반영한다는 뜻
from gensim.models.callbacks      import PerplexityMetric # 높을수록 의미론적 일관성 높음
from gensim.models.coherencemodel import CoherenceModel 
from gensim.models.ldamodel       import LdaModel 

import pyLDAvis
import pyLDAvis.gensim_models as gensimvis
pyLDAvis.enable_notebook()

data     = 'Y:/SeeValue/ipynb/Python/Project/BigKinds/data'
뉴스 식별자	일자	언론사	기고자	제목	통합 분류1	통합 분류2	통합 분류3	사건/사고 분류1	사건/사고 분류2	사건/사고 분류3	인물	위치	기관	키워드	특성추출(가중치순 상위 50개)	본문	URL	분석제외 여부
01101001.20210906150947002	20210906	한겨레	서정민	언론중재위 “열람차단청구권, 언론자유 침해 아냐”	사회>미디어	 IT_과학>보안	 정치>정치일반						전국언론노동조합,언론중재위,청구,국회,한국기자협회	언론,중재위,열람,차단,청구,언론,자유,침해,언론중재위원회,언론,중재법,개정안,포함,열람차단청구권,가능성,언론,자유,침해,가능,반박,언론중재위,보도,자료,열람차단청구권,언론,자유,침해,견해,오해,열람차단청구권,임시조치,사후,구제,수단,피해자,청구,차단,심리,언론사,합의,설명,국회,논의,언론,중재법,개정안,언론,보도,피해자,제목,전체적,맥락,본문,진실,기사,개인,신체,신념,영역,사생활,핵심,영역,침해,기사,인격권,계속적,침해,열람,청구,사안,관심,보도,여론형성,기여,보도,대상,열람,차단,청구,제외,전국언론노동조합,한국기자협회,언론,현업,단체,정치인,무책임,발언,대기업,불법,노동,행위,기사,열람차단,적용,반대,언론중재위,자료,가지,언론,자유,침해,가능,일축,피해자,일방,주장,인터넷,보도,열람,차단,언론사,동의,필수적,열람차단청구권,사전,조치,사후,조치,사전,조치,정보통신망법상,임시조치,제도,열람차단청구권,실무적,정착,관행,제도화,현행법,정정,보도,반론,보도,청구,실효,보완,의미,효과,열람차단청구권,언론중재위,마지막,열람차단청구권,사실,보도,사생활,핵심,영역,인격권,본질적,침해,보도,적용,공익,여론형성,부합,열람차단청구,제한,언론중재법,개정안,재검토,주장	열람차단청구권,피해자,개정안,언론중재법,중재위,언론중재위,열람차단,언론사,임시조치,여론형성,인격권,사생활,가능성,무책임,정치인,대기업,현행법,한국기자협회,한국,통신망법,제도화,전국언론노동조합,정보통신망법상,위원회,노동조합	"언론중재위원회가 언론중재법 개정안에 포함된 열람차단청구권에 대해 언론자유 침해 가능성을 반박하고 나섰다.

 언론중재위는 6일 보도자료를 내어 “열람차단청구권이 도입되면 언론의 자유가 크게 침해된다는 견해에는 많은 오해가 있다”며 “열람차단청구권은 임시조치와는 다른 사후적 구제수단으로, 피해자 청구만으로 차단되지 않고 심리 후 언론사와 합의를 거쳐야 한.."	http://www.hani.co.kr/arti/society/media/1010618.html	
01100201.20210906150944001	20210906	국민일보	김이현	민주, ‘경선 방역수칙 위반’ 논란에 “방역지침 계도”	정치>선거	 지역>충북	 지역>광주				강민진,한준호	충청권,대구	노동자 집회,청년정의당,정부,민주,더불어민주당,민주노총,선관위	민주,위반,경선,방역,수칙,논란,방역,지침,계도,민주,노총,집회,비교,이중,잣대,지적도,더불어민주당,대선,후보,지역,순회,경선,현장,방역,수칙,위반,제기,차원,선관위,최대,계도,활동,진행,결정,대변인,한준호,선관위,지지자들,최대,권고,선관위,역할,합동,연설회장,외부,공간,모임,차단,지지자들,방역지침,계도,예정,경선,주말,충청,행사장,바깥,지지자들,방역,수칙,위반,지적,정부,활동,방역,수칙,위반,대표,강민진,청년정의당,노동자,집회,활동,지적,정부,이중,잣대,비판,대변인,민주노총,방역,위반,사람들,집회,차단,지지층,민주노총,노조원,설명,선관위,상황,이날,코로나19,대구,경북,경선,대의원,현장,투표,온라인,ARS,투표,전환,결정,사전,현장투표,신청,국민,일반당원,현장투표,가능	선관위,민주노총,지지자들,현장투표,대변인,지지자,방역지침,코로나19,청년정의당,더불어민주당,강민진,한준호,대의원,일반당원,온라인,행사장,연설회장,당원,대구,충청,지적도,지지층,노조원,경북,노동자,사람들	"더불어민주당 대선 후보 지역순회 경선 현장서 방역수칙 위반 문제가 제기되자, 당 선관위 차원에서 최대한 모이지 않도록 계도 활동을 진행하기로 결정했다. 
 
한준호 선관위 대변인은 6일 기자들과 만나 “지지자들이 최대한 모이지 않도록 권고하고 이끌어나가는 것이 (당) 선관위의 역할”이라며 “합동연설회장 외부에 모일 수 있는 공간에 대해서 (모임을) 차단.."	http://news.kmib.co.kr/article/view.asp?arcid=0016242233&code=61111111&cp=kd	
01100201.20210906150740001	20210906	국민일보	안명진	정의당 “노동자 집회는 구속, 與 경선 인파는 무죄냐”	정치>국회_정당	 정치>선거	 정치>북한				송영길,강민진,손,손영래,여영국,노조	공평,대전,충남	정의당,청년정의당,정부,민주당,경찰청장,더불어민주당,중앙사고수습본부,민주노총 위원장,페이스북,합동연설회	집회,정의당,노동자,구속,인파,경선,무죄,정부,경선,정부,정당법,활동,공적,활동,설명,집회,정의당,노동자,활동,반박,대표,여영국,정의당,민주,노총,위원장,구속적부심,석방,대선,유세,핑계,방역지침,대표,송영길,더불어민주당,방치,경찰청장,고발,검토,대표,6일,모두발언,정의당,대표단,회의,발언,공평,집행,주장,코로나,시국,생존권,박탈,노동자들,코로나,방역,지침,대표,인신,구속,잔인,사회,정의당,강조,대표,강민진,청년정의당,민주당,대전,충남,합동연설회,행사장,현장,행사장,인산인해,사진,거리,사실,대표,유죄,민주당,자당,인산인,합동연설회,개최,경제위기,벼랑,경제,위기,벼랑,노동자들,집회,경찰,투입,노조,위원장,구속,정도,중범죄,비판,정부,합동연설회,정당,경선,행사,법률,활동,거리,체계,적용,논란,사회전략반장,손영래,중앙,사고,수습,본부,사회,전략,반장,이날,질의,자체,후보,경선,정당법,법률,부여,활동,활동,제한,모임,거리,체계,적용,반장,경선,자체,행사,당국,대규모,행사,일반,원칙,적용,요청,대표,페이스북,노동자,집회,사람,위험,민주당,경선장,위험,궤변,답변,반박,민주당,경선,활동,노동자,집회,활동,노동조합,헌법,보장,조직,강조,대표,정부,방역,걱정,노동자,집회,연설회,여당,경선,기준,제한,방역,중요,숫자,사람,거리,여부,정부,규탄,노동자,집회,정권연장,경선,여당,대선,중요	정의당,노동자,민주당,위원장,연설회,코로나,손영래,행사장,경제위기,합동연설회,정당법,더불어민주당,노동자들,방역지침,청년정의당,송영길,강민진	"여영국 정의당 대표가 “민주노총 위원장이 구속적부심에서 석방되지 않는다면, 대선 유세를 핑계로 방역지침을 어긴 송영길 더불어민주당 대표와 이를 방치한 경찰청장에 대한 고발을 심각하게 검토하겠다”고 밝혔다. 
 
여 대표는 6일 오전 열린 정의당 대표단회의 모두발언에서 “법은 공평하게 집행되어야 한다”면서 이같이 주장했다. 그는 “특히 코로나 시국에 생존.."	http://news.kmib.co.kr/article/view.asp?arcid=0016242221&code=61111111&cp=kd	


len(document), document.columns

document.groupby(document['category']).count()

pd.crosstab(index=document['category'], columns=document['bigkinds'], margins=True, dropna=True)

def data_4_lda(category=1):
    document_cat = document[document.category == category]
    document_cat.reset_index(inplace=True, drop=True)
    
    processed_data = []
    
    for str in document_cat.bigkinds_nouns:
        if pd.isna(str) == False :
            processed_data.append(str.split(' '))
        elif pd.isna(str) == True :
            processed_data.append(['Nan'])      
            
    dictionary = corpora.Dictionary(processed_data)
    corpus     = [dictionary.doc2bow(text) for text in processed_data] # 데이터를 벡터화시키기
    
    return document_cat, dictionary, corpus

def run_lda(dictionary, corpus, category=1):
    if category == 1:   # 정치
        topics = 7
    elif category == 2: # 경제
        topics = 14
    elif category == 3: # 사회
        topics = 10
    elif category == 4: # 문화
        topics = 11
    elif category == 5: # 국제
        topics = 9
    elif category == 6: # 지역
        topics = 15
    elif category == 7: # 스포츠
        topics = 11
    elif category == 8: # IT_과학
        topics = 6
    elif category == 9: # 미분류
        topics = 1
        
    perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell') 
    coherence_logger  = CoherenceMetric(corpus=corpus, coherence="u_mass", logger='shell') 
    lda_model         = LdaModel(corpus, id2word=dictionary, num_topics=topics, random_state=1, passes=30, callbacks=[coherence_logger, perplexity_logger]) 
    topics            = lda_model.print_topics(num_words=5) 

    for topic in topics: 
        print(topic) 
        
    return lda_model

def save_model(category=1):
    pickle.dump(corpus, open('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/corpus.pkl', 'wb'))
    dictionary.save('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/dictionary.gensim') 
    lda_model.save('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/lda_model.gensim')
    
    vis = gensimvis.prepare(lda_model, corpus, dictionary, sort_topics=False) 
    pyLDAvis.save_html(vis, 'Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/vis.html')

def load_model(category=1):
    dictionary = corpora.Dictionary.load('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/dictionary.gensim') 
    lda_model  = LdaModel.load('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/lda_model.gensim')
    print(lda_model.show_topic(0))
    return lda_model, dictionary

def apply_model(category=1):
    lst = []

    for i in range(len(corpus)):
        doc_topic_dist   = lda_model.get_document_topics(corpus[i], minimum_probability=0)
        sorted_doc_topic = sorted(doc_topic_dist, key=lambda x:x[1], reverse=True)
        lst.append(sorted_doc_topic[0])
        
    topics   = pd.DataFrame(lst, columns=['topic_id','prob'])
    df_topic = pd.concat([document_cat, topics], axis=1)        

    df_topic.to_excel('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/df_topic.xlsx')
        
    print(pd.crosstab(index=df_topic['bigkinds'], columns=df_topic['topic_id']))
    
    cross_table = pd.crosstab(index=df_topic['bigkinds'], columns=df_topic['topic_id'])
    cross_table.to_excel('Y:/SeeValue/ipynb/Python/Project/BigKinds/model/cat'+str(category)+'/cross_table.xlsx')
    
    return cross_table

for i in range(1,3): # range(1,8)을 사용하면 8개 주제를 동시에 실행 
    print('LDA 모델링을 위한 데이터 준비중', end='')
    document_cat, dictionary, corpus = data_4_lda(category=i)
    print('.......done!')
    print('LDA 모델링 실행', end='')
    lda_model = run_lda(dictionary, corpus, category=i)
    print('.......done!')
    print('LDA 모델 결과물 저장', end='')
    save_model(category=i)
    print('.......done!')
    print('LDA 모델 적용', end='')
    cross_table = apply_model(category=i)
    print('.......done!')
    print()

for i in range(3,8):
    print('LDA 모델링 Category = ', i)
    print('LDA 모델링을 위한 데이터 준비중', end='')
    document_cat, dictionary, corpus = data_4_lda(category=i)
    print('.......done!')
    print('LDA 모델링 실행', end='')
    lda_model = run_lda(dictionary, corpus, category=i)
    print('.......done!')
    print('LDA 모델 결과물 저장', end='')
    save_model(category=i)
    print('.......done!')
    print('LDA 모델 적용', end='')
    cross_table = apply_model(category=i)
    print('.......done!')
    print()



"""https://stackabuse.com/python-for-nlp-working-with-the-gensim-library-part-2/

http://doc.mindscale.kr/km/unstructured/notebook/08_topic.html
"""

lda_model, dictionary = load_model(category=1)

data     = 'Y:/SeeValue/ipynb/data' # 실제 데이터 저장 장소로 변경
corona   = pd.read_excel(data+'/corona.xlsx', dtype={'뉴스식별자':str})
print('컬럼명(corona.xlsx) : ')
print(corona.columns, '\n')

len(corona), corona.columns

corona['본문'][0]

corona.groupby(corona['통합 분류1']).count()

corona['본문'] = corona['본문'].str.replace(pat=r'[^0-9A-Za-z가-힣ㄱ-ㅎ@ ]', repl=r'', regex=True)

from tqdm import tqdm

import konlpy
from konlpy.tag import Mecab

mecab = Mecab(dicpath="C:/mecab/mecab-ko-dic/")

lines = corona['본문']

results   = []
words_all = []

print('[명사 추출 중입니다.]')
for line in tqdm(lines):
    r = []
    malist = mecab.nouns(line)
    for word in malist:
        if len(word) > 1 and word.isdigit() == False: # 두 글자 이상이면서 숫자가 아닌 경우만 저장
            r.append(word)
            words_all.append(word)
    r1 = (" ".join(r)).strip()
    results.append(r1)     
print('[명사 추출을 완료하였습니다.]\n')
print("추출된 전체 단어 수 : ", len(words_all))
print("추출된 단어 수      : ", len(set(words_all)))
print('\n')

processed_data = []
for str in results:
    if pd.isna(str) == False :
        processed_data.append(str.split(' '))
    elif pd.isna(str) == True :
        processed_data.append(['Nan'])

corpus = [dictionary.doc2bow(text) for text in processed_data] # 데이터를 벡터화시키기
len(corpus)

lst = []

for i in range(len(corpus)):
    doc_topic_dist   = lda_model.get_document_topics(corpus[i], minimum_probability=0)
    sorted_doc_topic = sorted(doc_topic_dist, key=lambda x:x[1], reverse=True)
    lst.append(sorted_doc_topic[0])
    
topics   = pd.DataFrame(lst, columns=['topic_id','prob'])
df_topic = pd.concat([corona, topics], axis=1)        
    
# pd.crosstab(index=df_topic['bigkinds'], columns=df_topic['topic_id'])

df_topic.head(3)













